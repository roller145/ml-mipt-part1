{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 Наивный байес и центроидный классификатор\n",
    "\n",
    "$p(x^{(k)}|y) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\cdot e^{-\\frac{(x^{(k)} - \\mu_{y^{(k)}})^2}{2 \\sigma^2}}$ \n",
    "\n",
    "В наивном байесовском подходе $classify(x) = arg \\smash{\\displaystyle\\max_y p(y)} \\cdot \\displaystyle \\prod_{k = 1}^{n} p(x^{(k)}|y) =$|так как классы имеют одинаковые априорные вероятности|$=arg \\smash{\\displaystyle\\max_y } \\displaystyle \\prod_{k = 1}^{n} p(x^{(k)}|y) =$|прологарифлированное выраение сохраняет максимумы, избавимся от констант, домножим на (-1)|$= arg \\smash{\\displaystyle\\min_y } \\displaystyle \\sum_{k = 1}^{n} (x^{(k)} - \\mu_{y^{(k)}})^2$\n",
    "\n",
    "Итоговое выражение под знаком суммы эквивалентно расстоянию до центра класса, что  и означает, что классификация сводится к отнесению объекта $x$ к классу $y$, центр которого $\\mu_y$ ближе всего к $x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 ROC-AUC случайных ответов\n",
    "\n",
    "$ROC-AUC= $|для случая, когда кривая строиться по трём точкам, можно явно выписать формулу площади |$ = \\displaystyle \\max_p (\\frac{1}{2} + \\frac{TPR - FNR}{2})$\n",
    "\n",
    "Рассмотрим матожидание величины $ TPR - FNR $ для фиксированного p:\n",
    "\n",
    "$E (TPR - FNR)  = E \\frac{TP }{(TP + FN)} - \\frac{ FP}{(FP + TN)} = \\frac{p \\cdot TrueActualClass}{TrueActualClass} - \\frac{p\\cdot FalseActualClass}{ FalseActualClass } = p  - p= 0$\n",
    "\n",
    "Значит, треугольный ROC-AUC для случайных ответов в среднем будет давать значение равное $\\frac{1}{2}$, причём независимо от p и долей классов "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3  Ошибка 1NN и оптимального байесовского классификатора\n",
    "\n",
    "$E_n = P(y \\ne y_n) = P(y = 1, y_n = 0| x, x_n) +  P(y = 0, y_n = 1| x, x_n) =  P(y = 1| x)\\cdot P(y_n = 0| x_n) + P(y = 0| x)\\cdot P(y_n = 1| x_n) = P(1| x)\\cdot P(0| x_n) + P(0| x)\\cdot P(1| x_n) \\overset{|x - x_n|->0}{\\longrightarrow}  P(1| x)\\cdot P(0| x) + P(0| x)\\cdot P(1| x) = 2\\cdot P(0| x)\\cdot P(1| x) = 2\\cdot \\max\\{P(0| x), P(1| x)\\} \\cdot \\min\\{P(0| x), P(1| x)\\} \\le 2 \\cdot \\min\\{P(0| x), P(1| x)\\} = 2 \\cdot E_B$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Ответы в листьях регрессионного дерева\n",
    "\n",
    "Рассмотрим математическое ожидание ошибки NxMSE для обоих случаев:\n",
    "\n",
    "1. $E \\displaystyle \\sum_{i = 1}^N (\\hat{y_i} - y_i)^2 = \\sum_{i = 1}^N E(\\hat{y_i} - y_i)^2 =\n",
    " \\sum_{i = 1}^N E\\hat{y_i}^2 + \\sum_{i = 1}^N E y_i^2 -2\\cdot \\sum_{i = 1}^N E {\\hat{y_i} \\cdot y_i} = \n",
    "\\sum_{i = 1}^N E\\hat{y_i}^2 + \\sum_{i = 1}^N E y_i^2 - 2 \\cdot \\sum_{i = 1}^N E \\hat{y_i} \\cdot y_i =\n",
    "N \\cdot (E {y_0})^2 + N \\cdot E y_0^2 - 2 N \\cdot E {y_0}\\cdot {\\hat{y_0}} \n",
    "$\n",
    "2. $E \\displaystyle \\sum_{i = 1}^N (\\hat{y_i} - y_i)^2 = \\sum_{i = 1}^N E(\\hat{y_i} - y_i)^2 =\n",
    " \\sum_{i = 1}^N E\\hat{y_i}^2 + \\sum_{i = 1}^N E y_i^2 -2\\cdot \\sum_{i = 1}^N E {\\hat{y_i} \\cdot y_i} = \n",
    "\\sum_{i = 1}^N E\\hat{y_i}^2 + \\sum_{i = 1}^N E y_i^2 - 2 \\cdot \\sum_{i = 1}^N E \\hat{y_i} \\cdot E y_i = N \\cdot E {y_0}^2 + N \\cdot E y_0^2 - 2 N \\cdot E {y_0}\\cdot {\\hat{y_0}}  \n",
    "$\n",
    "\n",
    "$\\Rightarrow$ MSE в первом случае не больше, чем во втором, так как \n",
    "$N \\cdot (E {y_0})^2 + N \\cdot E y_0^2 - 2 N \\cdot E {y_0}\\cdot {\\hat{y_0}} \\le N \\cdot E {y_0}^2 + N \\cdot E y_0^2 - 2 N \\cdot E {y_0}\\cdot {\\hat{y_0}}$ по неравенству Коши-Буняковского\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Unsupervised decision tree\n",
    "\n",
    "Найдём энтропию многомерного нормального распределения. Энтропия многомерного распределения выглядит как :\n",
    "$\\displaystyle H = - \\int_{-\\infty}^{+\\infty}...\\int_{-\\infty}^{+\\infty} p(x) \\cdot \\ln p(x) dx$\n",
    "\n",
    "Многомерное нормальное распределение с вектором матожидания $\\mu$ и матрицей ковариаций $\\Sigma$ имеет плотность вероятности :\n",
    "$p(x) = \\frac {1}{|\\Sigma|^{\\frac {1}{2}}  (2 \\pi)^{\\frac {n}{2}}} \\cdot e^{-\\frac {1}{2} \\cdot (x - \\mu)^T \\Sigma^{-1} (x-\\mu)}$\n",
    "\n",
    "Тогда энтропия многомерного нормального распределения будет иметь вид:\n",
    "$\\displaystyle H = - \\int_{-\\infty}^{+\\infty}...\\int_{-\\infty}^{+\\infty} p(x) \\cdot \\ln p(x) dx = - \\int_{-\\infty}^{+\\infty}...\\int_{-\\infty}^{+\\infty} p(x) \\cdot (-\\frac {1}{2} \\ln |\\Sigma| -\\frac {n}{2} \\ln{2 \\pi} -\\frac {1}{2} \\cdot (x - \\mu)^T \\Sigma^{-1} (x-\\mu)) dx = \\\\ \\int_{-\\infty}^{+\\infty}...\\int_{-\\infty}^{+\\infty} p(x) \\cdot (\\frac {1}{2} \\ln |\\Sigma| + \\frac {n}{2} \\ln{2 \\pi} + \\frac {1}{2} \\cdot (x - \\mu)^T \\Sigma^{-1} (x-\\mu)) dx  = \\\\\n",
    "E(\\frac {1}{2} \\ln |\\Sigma| + \\frac {n}{2} \\ln{2 \\pi} + \\frac {1}{2} \\cdot (x - \\mu)^T \\Sigma^{-1} (x-\\mu)) = \\\\\n",
    "\\frac {1}{2} \\ln |\\Sigma| + \\frac {n}{2} \\ln{2 \\pi} + \\frac {1}{2} \\cdot E( (x - \\mu)^T \\Sigma^{-1} (x-\\mu)) = \\\\\n",
    "\\frac {1}{2} \\ln |\\Sigma| + \\frac {n}{2} \\ln{2 \\pi} + \\frac {1}{2} \\cdot \\sum_{i=0}^{N}\\sum_{j = 0}^N E( (x_i - \\mu_i)^T \\Sigma^{-1}_{i,j} (x_j-\\mu_j)) = \n",
    "\\frac {1}{2} \\ln |\\Sigma| + \\frac {n}{2} \\ln{2 \\pi} + \\frac {1}{2} \\cdot \\sum_{i=0}^{N}\\sum_{j = 0}^N E( \\Sigma_{i,j} \\Sigma^{-1}_{i,j}) = \n",
    "\\frac {1}{2} \\ln |\\Sigma| + \\frac {n}{2} \\ln{2 \\pi} + \\frac {n}{2}   = \\\\ \\frac {1}{2} \\ln{ |\\Sigma| \\cdot (2 \\pi e)^n}\n",
    "$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
